{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c370d9",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04243c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.6)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/krishal/pes/code/sem-5/ML/ML miniproj/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Scikit-learn Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set pandas display option\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1df660",
   "metadata": {},
   "source": [
    "## data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533335e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using the correct relative path\n",
    "df = pd.read_csv('../data/raw/restaurant_reviews.csv')\n",
    "\n",
    "# Select the necessary columns and drop rows with missing ratings\n",
    "df = df[['Review','Rating']]\n",
    "df = df.dropna(subset=[\"Rating\", \"Review\"])\n",
    "\n",
    "# Ensure ratings are digits and convert the column to integer type\n",
    "df = df[df[\"Rating\"].apply(lambda x: str(x).isdigit())]\n",
    "df[\"Rating\"] = df[\"Rating\"].astype(int)\n",
    "\n",
    "# Ensure the 'Review' column is always a string\n",
    "df['Review'] = df['Review'].astype(str)\n",
    "\n",
    "print(\"Data loaded and cleaned successfully.\")\n",
    "print(f\"Shape of the dataframe: {df.shape}\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03983084",
   "metadata": {},
   "source": [
    "MAP rating and setiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6994bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(rating):\n",
    "    if rating > 3:\n",
    "        return \"positive\"\n",
    "    elif rating < 3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df[\"Sentiment\"] = df[\"Rating\"].apply(map_sentiment)\n",
    "\n",
    "print(\"Sentiment column created.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5796b6",
   "metadata": {},
   "source": [
    "check class balances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cf0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiment distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=\"Sentiment\", data=df, palette=\"coolwarm\", order=['positive', 'negative', 'neutral'])\n",
    "plt.title(\"Sentiment Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Sentiment\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Display the exact value counts\n",
    "print(\"Sentiment Value Counts (Normalized):\")\n",
    "print(df[\"Sentiment\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdedd7",
   "metadata": {},
   "source": [
    "text cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data (only needs to be done once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "print(\"Preprocessing function is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130afaa5",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae613ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the Review column\n",
    "# This may take a moment to run\n",
    "df['Processed_Review'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "print(\"Text preprocessing complete. Here's a before-and-after example:\")\n",
    "print(\"\\n--- ORIGINAL REVIEW ---\")\n",
    "print(df['Review'].iloc[0])\n",
    "print(\"\\n--- PROCESSED REVIEW ---\")\n",
    "print(df['Processed_Review'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5d4c3",
   "metadata": {},
   "source": [
    "TDF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "# max_features limits the vocabulary size to the top 5000 words\n",
    "# ngram_range=(1,2) considers both single words and pairs of words (bigrams)\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "# Create the feature matrix (X) and target vector (y)\n",
    "X = tfidf.fit_transform(df['Processed_Review'])\n",
    "y = df['Sentiment']\n",
    "\n",
    "print(\"TF-IDF vectorization complete.\")\n",
    "print(f\"Shape of the feature matrix (X): {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73324376",
   "metadata": {},
   "source": [
    "split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c241bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, # for reproducibility\n",
    "    stratify=y       # IMPORTANT for imbalanced data\n",
    ")\n",
    "\n",
    "print(\"Data splitting complete.\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf885b2",
   "metadata": {},
   "source": [
    "Apply SMOTE for Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original training set distribution: {Counter(y_train)}\")\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit and apply SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Resampled training set distribution: {Counter(y_train_resampled)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025e01c",
   "metadata": {},
   "source": [
    "Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187affcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "# We increase max_iter to ensure convergence\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac932a7",
   "metadata": {},
   "source": [
    "Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training and Evaluating Random Forest ---\")\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled_encoded)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\n--- Random Forest Evaluation ---\")\n",
    "print(classification_report(y_test_encoded, y_pred_rf, target_names=le.classes_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e55689",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd646897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training and Evaluating XGBoost ---\")\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=3, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled_encoded)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"\\n--- XGBoost Evaluation ---\")\n",
    "print(classification_report(y_test_encoded, y_pred_xgb, target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1175c",
   "metadata": {},
   "source": [
    "model eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 scores for the neutral class for each model\n",
    "f1_neutral_log_reg = f1_score(y_test_encoded, y_pred_log_reg, labels=[le.transform(['neutral'])[0]], average='macro')\n",
    "f1_neutral_rf = f1_score(y_test_encoded, y_pred_rf, labels=[le.transform(['neutral'])[0]], average='macro')\n",
    "f1_neutral_xgb = f1_score(y_test_encoded, y_pred_xgb, labels=[le.transform(['neutral'])[0]], average='macro')\n",
    "\n",
    "print(f\"Logistic Regression Neutral F1-Score: {f1_neutral_log_reg:.4f}\")\n",
    "print(f\"Random Forest Neutral F1-Score: {f1_neutral_rf:.4f}\")\n",
    "print(f\"XGBoost Neutral F1-Score: {f1_neutral_xgb:.4f}\")\n",
    "\n",
    "# For this example, let's assume XGBoost performed best and analyze its errors\n",
    "print(\"\\n--- Analyzing Misclassified Neutral Reviews (from XGBoost model) ---\")\n",
    "\n",
    "# Decode predictions back to string labels for analysis\n",
    "y_pred_xgb_labels = le.inverse_transform(y_pred_xgb)\n",
    "\n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame({'True_Sentiment': y_test, 'Predicted_Sentiment': y_pred_xgb_labels})\n",
    "results_df['Review'] = df.loc[y_test.index, 'Review']\n",
    "\n",
    "# Filter for misclassified neutral reviews\n",
    "misclassified_neutral = results_df[\n",
    "    (results_df['True_Sentiment'] == 'neutral') & \n",
    "    (results_df['Predicted_Sentiment'] != 'neutral')\n",
    "]\n",
    "\n",
    "print(f\"\\nNumber of misclassified neutral reviews: {len(misclassified_neutral)}\")\n",
    "print(\"Displaying 10 examples:\")\n",
    "print(misclassified_neutral.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
